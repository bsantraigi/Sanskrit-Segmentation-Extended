{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Header"
    ]
   },
   "source": [
    "#### MP based asynchronous testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "Header"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import TestPool_Unit\n",
    "from shutil import copyfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluate(result_arr):\n",
    "    print('Files Processed: ', len(result_arr))\n",
    "    recalls = []\n",
    "    recalls_of_word = []\n",
    "    precisions = []\n",
    "    precisions_of_words = []\n",
    "    fully_Correct_l = 0\n",
    "    fully_Correct_w = 0\n",
    "    for entry in result_arr:\n",
    "        (word_match, lemma_match, n_dcsWords, n_output_nodes) = entry\n",
    "        recalls.append(lemma_match/n_dcsWords)\n",
    "        recalls_of_word.append(word_match/n_dcsWords)\n",
    "\n",
    "        precisions.append(lemma_match/n_output_nodes)\n",
    "        precisions_of_words.append(word_match/n_output_nodes)\n",
    "        if lemma_match == n_dcsWords:\n",
    "            fully_Correct_l += 1\n",
    "        if word_match == n_dcsWords:\n",
    "            fully_Correct_w += 1\n",
    "    print('Avg. Micro Recall of Lemmas: {}'.format(np.mean(np.array(recalls))))\n",
    "    print('Avg. Micro Recall of Words: {}'.format(np.mean(np.array(recalls_of_word))))\n",
    "    print('Avg. Micro Precision of Lemmas: {}'.format(np.mean(np.array(precisions))))\n",
    "    print('Avg. Micro Precision of Words: {}'.format(np.mean(np.array(precisions_of_words))))\n",
    "    rl = np.mean(np.array(recalls))\n",
    "    pl = np.mean(np.array(precisions))\n",
    "    print('F-Score of Lemmas: ', (2*pl*rl)/(pl+rl))\n",
    "    print('Fully Correct Lemmawise: {}'.format(fully_Correct_l/len(recalls_of_word)))\n",
    "    print('Fully Correct Wordwise: {}'.format(fully_Correct_w/len(recalls_of_word)))\n",
    "    print('[{:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}, {:0.2f}]'.format(100*np.mean(np.array(recalls)), 100*np.mean(np.array(recalls_of_word)), 100*np.mean(np.array(precisions)), \\\n",
    "           100*np.mean(np.array(precisions_of_words)), 100*(2*pl*rl)/(pl+rl), 100*fully_Correct_l/len(recalls_of_word),\\\n",
    "           100*fully_Correct_w/len(recalls_of_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child process with vpid:0, pid:4932 started.\n",
      "Child process with vpid:1, pid:4933 started.\n",
      "Child process with vpid:2, pid:4938 started.\n",
      "Child process with vpid:3, pid:4943 started.\n",
      "Child process with vpid:4, pid:4944 started.\n",
      "Child process with vpid:5, pid:4947 started.\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:1: Range is 1600 -> 3200 / 9577\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:5: Range is 8000 -> 9600 / 9577\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:0: Range is 0 -> 1600 / 9577\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:3: Range is 4800 -> 6400 / 9577\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:2: Range is 3200 -> 4800 / 9577\n",
      "Keep Prob = 0.6, Dropout = 0.4\n",
      "vpid:4: Range is 6400 -> 8000 / 9577\n"
     ]
    }
   ],
   "source": [
    "modelFile = 'outputs/train_t2789415023871/nnet_e1_i400.p' #BR2\n",
    "_dump = False\n",
    "if _dump:\n",
    "    _outFile = 'outputs/dump_predictions/BR2_NLoss'\n",
    "else:\n",
    "    _outFile = None\n",
    "\n",
    "# Backup the model file\n",
    "copyfile(modelFile, modelFile + '.bk')\n",
    "\n",
    "# Create Queue, Result array\n",
    "queue = mp.Queue()\n",
    "result_arr = []\n",
    "\n",
    "# Start 6 workers - 8 slows down the pc\n",
    "proc_count = 6\n",
    "procs = [None]*proc_count\n",
    "for i in range(proc_count):\n",
    "    vpid = i\n",
    "    procs[i] = mp.Process(target = TestPool_Unit.pooled_Test, args = \\\n",
    "                          (modelFile, vpid, queue, '../NewData/skt_dcs_DS.bz2_4K_bigram_rfe_heldout/', int(9600/proc_count), _dump, _outFile))\n",
    "# Start Processes\n",
    "for i in range(proc_count):\n",
    "    procs[i].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Processed:  8043\n",
      "Avg. Micro Recall of Lemmas: 0.8647977788996555\n",
      "Avg. Micro Recall of Words: 0.7351168084504492\n",
      "Avg. Micro Precision of Lemmas: 0.8200023294654187\n",
      "Avg. Micro Precision of Words: 0.6978388400928252\n",
      "F-Score of Lemmas:  0.841804543688\n",
      "Fully Correct Lemmawise: 0.43777197563098347\n",
      "Fully Correct Wordwise: 0.18115131169961457\n",
      "[86.48, 73.51, 82.00, 69.78, 84.18, 43.78, 18.12]\n"
     ]
    }
   ],
   "source": [
    "# Fetch partial results\n",
    "while not queue.empty():\n",
    "    result_arr.append(queue.get())\n",
    "# Evaluate results till now\n",
    "Evaluate(result_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process with\t vpid: 0\t ->\t pid: 4932\t ->\t running status: False\n",
      "Process with\t vpid: 1\t ->\t pid: 4933\t ->\t running status: False\n",
      "Process with\t vpid: 2\t ->\t pid: 4938\t ->\t running status: False\n",
      "Process with\t vpid: 3\t ->\t pid: 4943\t ->\t running status: False\n",
      "Process with\t vpid: 4\t ->\t pid: 4944\t ->\t running status: False\n",
      "Process with\t vpid: 5\t ->\t pid: 4947\t ->\t running status: False\n"
     ]
    }
   ],
   "source": [
    "# Check status\n",
    "for i in range(proc_count):\n",
    "    p = procs[i]\n",
    "    print('Process with\\t vpid: {}\\t ->\\t pid: {}\\t ->\\t running status: {}'.format(i, p.pid, p.is_alive()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Properly Join\n",
    "for i in range(proc_count):\n",
    "    procs[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Force Terminate\n",
    "for p in procs:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.7729026036644164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([a[2] for a in result_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1, Samples: 199, Mean: 0.7537688442211056\n",
      "C: 2, Samples: 428, Mean: 0.8259345794392523\n",
      "C: 3, Samples: 293, Mean: 0.8612059158134243\n",
      "C: 4, Samples: 260, Mean: 0.8096153846153846\n",
      "C: 5, Samples: 646, Mean: 0.8328173374613003\n",
      "C: 6, Samples: 2004, Mean: 0.8733366600133068\n",
      "C: 7, Samples: 2653, Mean: 0.8951052716601151\n",
      "C: 8, Samples: 1885, Mean: 0.8915119363395225\n",
      "C: 9, Samples: 714, Mean: 0.886710239651416\n",
      "C: 10, Samples: 208, Mean: 0.8764423076923078\n",
      "C: 11, Samples: 92, Mean: 0.8922924901185771\n",
      "C: 12, Samples: 75, Mean: 0.8522222222222222\n",
      "C: 13, Samples: 24, Mean: 0.842948717948718\n",
      "C: 14, Samples: 19, Mean: 0.8759398496240601\n",
      "C: 15, Samples: 16, Mean: 0.8333333333333334\n",
      "C: 16, Samples: 8, Mean: 0.890625\n",
      "C: 17, Samples: 14, Mean: 0.8403361344537814\n",
      "C: 18, Samples: 8, Mean: 0.8333333333333334\n",
      "C: 19, Samples: 5, Mean: 0.8315789473684211\n",
      "C: 20, Samples: 2, Mean: 0.925\n",
      "C: 21, Samples: 4, Mean: 0.8809523809523809\n",
      "C: 22, Samples: 2, Mean: 0.7954545454545454\n",
      "C: 23, Samples: 3, Mean: 0.7826086956521738\n",
      "C: 24, Samples: 1, Mean: 0.7083333333333334\n",
      "C: 26, Samples: 4, Mean: 0.7403846153846153\n",
      "C: 28, Samples: 2, Mean: 0.8035714285714286\n",
      "C: 29, Samples: 2, Mean: 0.8793103448275862\n",
      "C: 30, Samples: 1, Mean: 0.8\n",
      "C: 32, Samples: 1, Mean: 0.8125\n",
      "C: 33, Samples: 1, Mean: 0.7878787878787878\n",
      "C: 35, Samples: 1, Mean: 0.6857142857142857\n",
      "C: 37, Samples: 1, Mean: 0.8378378378378378\n",
      "C: 46, Samples: 1, Mean: 0.8913043478260869\n"
     ]
    }
   ],
   "source": [
    "result_arr2 = [list(x) for x in result_arr]\n",
    "\n",
    "recalls = defaultdict(list)\n",
    "for i in range(len(result_arr2)):\n",
    "    result_arr2[i][0] /= result_arr2[i][2]\n",
    "    result_arr2[i][1] /= result_arr2[i][2]\n",
    "    recalls[result_arr2[i][2]].append(result_arr2[i][1])\n",
    "\n",
    "for c in sorted(recalls.keys()):\n",
    "    print('C: {}, Samples: {}, Mean: {}'.format(c, len(recalls[c]), np.mean(recalls[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ENV(py3_bishal)",
   "language": "python",
   "name": "py3_bishal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
