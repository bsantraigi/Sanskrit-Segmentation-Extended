{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sentences, DCS\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = json.load(open('../NewData/data7.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(D.keys()))\n",
    "d_keys = list(D.keys())\n",
    "print(d_keys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-200\n",
      "-230\n",
      "-220\n",
      "-240\n",
      "-190\n",
      "-210\n"
     ]
    }
   ],
   "source": [
    "for k in d_keys:\n",
    "    ki = abs(int(k))\n",
    "    if(ki >= 190 and ki <= 240):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _getPathValue(terminal_1, path_type, terminal_2):\n",
    "    p = 0;\n",
    "    return p\n",
    "        \n",
    "def GetPathVector(terminal_1, terminal_2):\n",
    "    x = np.array([0]*len(all_path_types))\n",
    "    for i in range(len(all_path_types)):\n",
    "        path = all_path_types[i]\n",
    "        x[i] = _getPathValue(terminal_1, path, terminal_2)        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting CNG GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentences import *\n",
    "from DCS import *\n",
    "import json\n",
    "import numpy as np\n",
    "from romtoslp import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaded_DCS = pickle.load(open('../Simultaneous_DCS.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100078"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SKT = pickle.load(open('../Simultaneous_CompatSKT.p', 'rb'))\n",
    "len(loaded_SKT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cng_Groups(sentenceObj, dDict):\n",
    "    #print('SKT ANALYZE')\n",
    "    #print('-'*15)\n",
    "    #print(sentenceObj.sentence)\n",
    "    zz = 0\n",
    "    # (chunkDict, lemmaList, wordList, revMap2Chunk, qu, cngList, verbs, tuplesMain) = SentencePreprocess(sentenceObj)\n",
    "    # for cid in chunkDict.keys():\n",
    "    #     print('Analyzing:', rom_slp(sentenceObj.chunk[cid].chunk_name))\n",
    "    #     for pos in chunkDict[cid].keys():\n",
    "    #         tupIds = chunkDict[cid][pos]\n",
    "    #         for ti in tupIds:\n",
    "    #             print('%d :' % (pos, ), end = ' ')\n",
    "    #             print(tuplesMain[ti][0][1], end=' ')\n",
    "    #             for tup in tuplesMain[ti]:\n",
    "    #                 print([zz, tup[2], tup[3]], end=' ')\n",
    "    #                 zz += 1\n",
    "    #             print('')\n",
    "    #     print('-'*25)\n",
    "\n",
    "    for chunk in sentenceObj.chunk:\n",
    "        # print(\"Analyzing \", rom_slp(chunk.chunk_name))\n",
    "        for pos in chunk.chunk_words.keys():\n",
    "            for word_sense in chunk.chunk_words[pos]:\n",
    "                #word_sense = fix_w_new(word_sense)\n",
    "                #print(word_sense.forms)\n",
    "                for form_dict in word_sense.forms:\n",
    "                    if isinstance(form_dict, dict):                        \n",
    "                        for key, val_arr in form_dict.items():\n",
    "                            #print('Key: ', key)\n",
    "                            #print('Val Array: ', val_arr)\n",
    "                            for val in val_arr:\n",
    "                                if isinstance(val, list):\n",
    "                                    if len(val) > 1:\n",
    "                                        print('Key: ', key)\n",
    "                                        print('Bad Val: ', val, ' Size: ', len(val))\n",
    "                                    dDict[key].add(val[0])\n",
    "                                else:\n",
    "                                    dDict[key].add(val)\n",
    "                # for formsDict in word_sense.forms:\n",
    "                #     print(getCNGs(formsDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DD = defaultdict(lambda:set())\n",
    "i = 0\n",
    "for key, val in loaded_SKT.items():\n",
    "    i += 1\n",
    "    cng_Groups(val, DD)\n",
    "    if i==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dict(DD), open('cng_grps_dd.p', 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Verb CNG Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sentences import *\n",
    "from DCS import *\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from IPython.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Lem2CNG and CNG2Lem Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat_lem2cng = pickle.load(open('../NewData/mat_lem2cng.p', 'rb'), encoding='utf-8')\n",
    "mat_cng2lem = pickle.load(open('../NewData/mat_cng2lem.p', 'rb'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, -35, 116, 175, -123, 28, 36, -83, -52, 99]\n",
      "276\n"
     ]
    }
   ],
   "source": [
    "all_cngs = list(int(vc) for vc in list(mat_cng2lem.keys()))\n",
    "print(all_cngs[0:10])\n",
    "print(len(all_cngs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'1': {0},\n",
       "             '10': {1, 2, 3, 4, 6, 7, 8, 9},\n",
       "             '11': {1, 2, 3, 4, 9},\n",
       "             '12': {1, 2, 3, 4, 5, 7, 9},\n",
       "             '13': {1, 2, 3, 6, 9},\n",
       "             '14': {1, 2, 3, 7, 9},\n",
       "             '15': {0, 1, 2, 3, 4, 7, 9},\n",
       "             '16': {1, 2, 3, 4, 6, 7, 8, 9},\n",
       "             '17': {1, 3, 6, 9},\n",
       "             '19': {0},\n",
       "             '2': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       "             '20': {0},\n",
       "             '21': {0},\n",
       "             '22': {0},\n",
       "             '23': {0},\n",
       "             '24': {0},\n",
       "             '25': {1, 2, 3, 5, 6, 7, 9},\n",
       "             '26': {0},\n",
       "             '27': {1, 2, 3, 6, 8, 9},\n",
       "             '28': {1, 3, 6, 9},\n",
       "             '29': {3},\n",
       "             '3': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       "             '30': {1, 2, 3, 6, 7, 9},\n",
       "             '31': {1, 2, 3, 6, 7, 8, 9},\n",
       "             '4': {1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       "             '5': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       "             '6': {1, 2, 3, 4, 5, 6, 7, 8, 9},\n",
       "             '7': {1, 2, 3, 4, 6, 7, 8, 9},\n",
       "             '8': {1, 2, 3, 6, 7, 8, 9},\n",
       "             '9': {0, 1, 2, 3, 4, 6, 7, 9}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tense_classes = defaultdict(lambda:set())\n",
    "for vc in all_cngs:\n",
    "    if vc < 0:\n",
    "        tense_classes[str(-math.floor(vc/10))].add((-vc)%10)\n",
    "tense_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'du': [4, 5, 6],\n",
       " 'fp': [1, 4, 7],\n",
       " 'pl': [7, 8, 9],\n",
       " 'sg': [1, 2, 3],\n",
       " 'sp': [2, 5, 8],\n",
       " 'tp': [3, 6, 9]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'du': [4, 5, 6],\n",
       " 'du_fp': {4},\n",
       " 'du_sp': {5},\n",
       " 'du_tp': {6},\n",
       " 'fp': [1, 4, 7],\n",
       " 'pl': [7, 8, 9],\n",
       " 'pl_fp': {7},\n",
       " 'pl_sp': {8},\n",
       " 'pl_tp': {9},\n",
       " 'sg': [1, 2, 3],\n",
       " 'sg_fp': {1},\n",
       " 'sg_sp': {2},\n",
       " 'sg_tp': {3},\n",
       " 'sp': [2, 5, 8],\n",
       " 'tp': [3, 6, 9]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num_person: encoding style\n",
    "verb_groups = defaultdict(lambda: set())\n",
    "number_forms = dict()\n",
    "number_forms['sg'] = [1, 2, 3]\n",
    "number_forms['du'] = [4, 5, 6]\n",
    "number_forms['pl'] = [7, 8, 9]\n",
    "\n",
    "person_forms = dict()\n",
    "person_forms['fp'] = [1, 4, 7]\n",
    "person_forms['sp'] = [2, 5, 8]\n",
    "person_forms['tp'] = [3, 6, 9]\n",
    "\n",
    "comb_forms = dict()\n",
    "comb_forms2 = dict()\n",
    "for key_num, num_vals in number_forms.items():\n",
    "    for key_person, person_vals in person_forms.items():\n",
    "        s = set()\n",
    "        for n in num_vals:\n",
    "            for p in person_vals:\n",
    "                if n==p:\n",
    "                    s.add(n)\n",
    "        comb_forms2['%s_%s'%(key_num, key_person)] = s\n",
    "comb_forms.update(number_forms)\n",
    "comb_forms.update(person_forms)\n",
    "comb_forms2.update(number_forms)\n",
    "comb_forms2.update(person_forms)\n",
    "display(comb_forms)\n",
    "display(comb_forms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verb_groups = dict()\n",
    "for tense in tense_classes.keys():\n",
    "    for form, mods in comb_forms.items():\n",
    "        new_key = '%s_%s'%(tense, form)\n",
    "        s = set()\n",
    "        for modulo in mods:\n",
    "            if modulo in tense_classes[tense]:\n",
    "                s.add(int(tense)*10 + modulo)\n",
    "        if len(s) > 0:\n",
    "            verb_groups[new_key] = list(s)\n",
    "\n",
    "for form, mods in comb_forms2.items():\n",
    "    new_key = form\n",
    "    s = set()\n",
    "    for modulo in mods:\n",
    "        for tense in tense_classes.keys():\n",
    "            if modulo in tense_classes[tense]:\n",
    "                s.add(int(tense)*10 + modulo)\n",
    "    if len(s) > 0:\n",
    "        verb_groups[new_key] = list(s)\n",
    "json.dump(verb_groups, open('json_n_pickle_Files/verbgroups.json', 'w'))\n",
    "# verb_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verb_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Noun CNG Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentences import *\n",
    "from DCS import *\n",
    "from IPython.display import display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noungroups = json.load(open('json_n_pickle_Files/noungroups.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noungroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# # PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sentences import *\n",
    "from DCS import *\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from IPython.display import display\n",
    "import json\n",
    "from ProbModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Started[Prob]...\n",
      "Dataloader Finished[Prob]...\n"
     ]
    }
   ],
   "source": [
    "# IMPORT THE DATALOADER FILES FIRST\n",
    "from utilities import *\n",
    "from collections import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"Dataloader Started[Prob]...\")\n",
    "\n",
    "fullCo_oc_mat = pickleFixLoad('extras/all_dcs_lemmas_matrix_countonly.p')\n",
    "unigram_counts = pickleFixLoad('../NewData/ultimate_new_lastsem/unigram_lemma_countonly.p')\n",
    "\n",
    "cng2cngFullMat = np.mat(pickle.load(open('extras/all_dcs_cngs_matrix_countonly.p','rb'), encoding = 'latin1'))\n",
    "cng2index_dict = pickleFixLoad('cng2index_dict.p')\n",
    "\n",
    "w2w_samecng_fullmat = pickle.load(open('extras/lemmas_with_same_cngs_matrix_countonly.p', 'rb'), encoding=u'utf-8')\n",
    "samecng_unigram_counts = pickle.load(open('extras/dictionary_for_lemmas_with_same_cng.p', 'rb'), encoding=u'utf-8')\n",
    "\n",
    "v2c_fullMat = pickle.load(open('extras/verbs_vs_cngs_matrix_countonly.p', 'rb'), encoding=u'utf-8')\n",
    "\n",
    "print(\"Dataloader Finished[Prob]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbModel = ProbModels(fullCo_oc_mat = fullCo_oc_mat, unigram_counts = unigram_counts,\n",
    "               cng2cngFullMat = cng2cngFullMat, cng2index_dict = cng2index_dict,\n",
    "               w2w_samecng_fullmat=w2w_samecng_fullmat, samecng_unigram_counts = samecng_unigram_counts,\n",
    "               v2c_fullMat = v2c_fullMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66914\n",
      "avarRaka advAra pratisrotas\n",
      "2.2026413966350114e-06\n"
     ]
    }
   ],
   "source": [
    "lemma_list = list(unigram_counts.keys())\n",
    "print(len(lemma_list))\n",
    "print(lemma_list[0], lemma_list[10], lemma_list[100])\n",
    "print(pbModel.kn_word2word(lemma_list[0], lemma_list[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_co_oc_count = pbModel.total_co_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pmi(x;y) = -log2[p(x|y)/p(x)]\n",
    "def PMI(x, y, _pbModel):\n",
    "    if(x in _pbModel.fullCo_oc_mat[y]):\n",
    "        p_x_given_y = _pbModel.fullCo_oc_mat[y][x]/_pbModel.unigram_counts[y]\n",
    "        p_x = _pbModel.unigram_counts[x]/_pbModel.unigram_total_count\n",
    "        #print(p_x_given_y, ' ', p_x)\n",
    "        return -math.log2(p_x_given_y/p_x)\n",
    "    else:\n",
    "        p_x_given_y = 1/_pbModel.unigram_counts[y]\n",
    "        p_x = _pbModel.unigram_counts[x]/_pbModel.unigram_total_count\n",
    "        #print(p_x_given_y, ' ', p_x)\n",
    "        return -math.log2(p_x_given_y/p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.307367596880127\n",
      "-19.307367596880127\n",
      "-20.629295691767492\n",
      "-20.629295691767492\n"
     ]
    }
   ],
   "source": [
    "print(PMI('vEdiSa', 'SatruGAtin', pbModel))\n",
    "print(PMI('SatruGAtin', 'vEdiSa', pbModel))\n",
    "\n",
    "print(PMI('anupavyAyacCamAna', 'SatruGAtin', pbModel))\n",
    "print(PMI('SatruGAtin', 'anupavyAyacCamAna', pbModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_PMI_Mat = defaultdict(lambda: {})\n",
    "count = 0\n",
    "for y, _ in fullCo_oc_mat.items():\n",
    "    count += 1\n",
    "    for x, _ in fullCo_oc_mat[y].items():\n",
    "        # print(y, x, fullCo_oc_mat[y][x])\n",
    "        # Getting PMI(x | y)\n",
    "        try:\n",
    "            v = PMI(x, y, pbModel)\n",
    "        except:\n",
    "            v = None\n",
    "        if v != None:\n",
    "            full_PMI_Mat[y][x] = v\n",
    "    if(count % 10000 ==0):\n",
    "        print(\"Checkpoint: \", count)\n",
    "full_PMI_Mat = dict(full_PMI_Mat)\n",
    "pickle.dump(full_PMI_Mat, open('../NewData/ultimate_new_lastsem/full_PMI_Mat.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y, x)\n",
    "print(pbModel.fullCo_oc_mat[y][x]/pbModel.unigram_counts[y])\n",
    "print(pbModel.unigram_counts[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullCo_oc_mat = pickleFixLoad('extras/all_dcs_lemmas_matrix_countonly.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strImalApahA', 'anaSitum', 'vijihma']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fullCo_oc_mat.keys())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
