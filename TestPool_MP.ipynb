{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Header"
    ]
   },
   "source": [
    "#### MP based asynchronous testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "Header"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import TestPool_Unit\n",
    "from shutil import copyfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Evaluate(result_arr):\n",
    "    print('Files Processed: ', len(result_arr))\n",
    "    recalls = []\n",
    "    recalls_of_word = []\n",
    "    precisions = []\n",
    "    precisions_of_words = []\n",
    "    fully_Correct_l = 0\n",
    "    fully_Correct_w = 0\n",
    "    for entry in result_arr:\n",
    "        (word_match, lemma_match, n_dcsWords, n_output_nodes) = entry\n",
    "        recalls.append(lemma_match/n_dcsWords)\n",
    "        recalls_of_word.append(word_match/n_dcsWords)\n",
    "\n",
    "        precisions.append(lemma_match/n_output_nodes)\n",
    "        precisions_of_words.append(word_match/n_output_nodes)\n",
    "        if lemma_match == n_dcsWords:\n",
    "            fully_Correct_l += 1\n",
    "        if word_match == n_dcsWords:\n",
    "            fully_Correct_w += 1\n",
    "    print('Avg. Micro Recall of Lemmas: {}'.format(np.mean(np.array(recalls))))\n",
    "    print('Avg. Micro Recall of Words: {}'.format(np.mean(np.array(recalls_of_word))))\n",
    "    print('Avg. Micro Precision of Lemmas: {}'.format(np.mean(np.array(precisions))))\n",
    "    print('Avg. Micro Precision of Words: {}'.format(np.mean(np.array(precisions_of_words))))\n",
    "    print('Fully Correct Lemmawise: {}'.format(fully_Correct_l/len(recalls_of_word)))\n",
    "    print('Fully Correct Wordwise: {}'.format(fully_Correct_w/len(recalls_of_word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child process with vpid:0, pid:29324 started.\n",
      "Child process with vpid:1, pid:29325 started.\n",
      "Child process with vpid:2, pid:29328 started.\n",
      "Child process with vpid:3, pid:29333 started.\n",
      "vpid:0: Range is 0 -> 2400 / 9577\n",
      "vpid:2: Range is 4800 -> 7200 / 9577\n",
      "vpid:1: Range is 2400 -> 4800 / 9577\n",
      "vpid:3: Range is 7200 -> 9600 / 9577\n"
     ]
    }
   ],
   "source": [
    "modelFile = 'outputs/train_t2009110446493/nnet_i50.p' #se_loss Rerun\n",
    "_dump = False\n",
    "if _dump:\n",
    "    _outFile = 'outputs/dump_predictions/pred_1L_bigram'\n",
    "else:\n",
    "    _outFile = None\n",
    "\n",
    "# Backup the model file\n",
    "copyfile(modelFile, modelFile + '.bk')\n",
    "\n",
    "# Create Queue, Result array\n",
    "queue = mp.Queue()\n",
    "result_arr = []\n",
    "\n",
    "# Start 6 workers - 8 slows down the pc\n",
    "proc_count = 4\n",
    "procs = [None]*proc_count\n",
    "for i in range(proc_count):\n",
    "    vpid = i\n",
    "    procs[i] = mp.Process(target = TestPool_Unit.pooled_Test, args = \\\n",
    "                          (modelFile, vpid, queue, '../NewData/skt_dcs_DS.bz2_1L_bigram_heldout/', 2400, _dump, _outFile))\n",
    "# Start Processes\n",
    "for i in range(proc_count):\n",
    "    procs[i].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Processed:  1209\n",
      "Avg. Micro Recall of Lemmas: 0.8449972847287107\n",
      "Avg. Micro Recall of Words: 0.7388494372146394\n",
      "Avg. Micro Precision of Lemmas: 0.7921270283574317\n",
      "Avg. Micro Precision of Words: 0.693247785837477\n",
      "Fully Correct Lemmawise: 0.3771712158808933\n",
      "Fully Correct Wordwise: 0.19106699751861042\n"
     ]
    }
   ],
   "source": [
    "# Fetch partial results\n",
    "while not queue.empty():\n",
    "    result_arr.append(queue.get())\n",
    "# Evaluate results till now\n",
    "Evaluate(result_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process with\t vpid: 0\t ->\t pid: 4770\t ->\t running status: False\n",
      "Process with\t vpid: 1\t ->\t pid: 4771\t ->\t running status: False\n",
      "Process with\t vpid: 2\t ->\t pid: 4772\t ->\t running status: False\n",
      "Process with\t vpid: 3\t ->\t pid: 4777\t ->\t running status: False\n"
     ]
    }
   ],
   "source": [
    "# Check status\n",
    "for i in range(proc_count):\n",
    "    p = procs[i]\n",
    "    print('Process with\\t vpid: {}\\t ->\\t pid: {}\\t ->\\t running status: {}'.format(i, p.pid, p.is_alive()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Properly Join\n",
    "for i in range(proc_count):\n",
    "    procs[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Force Terminate\n",
    "for p in procs:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.7729026036644164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([a[2] for a in result_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1, Samples: 110, Mean: 0.7545454545454545\n",
      "C: 2, Samples: 245, Mean: 0.8244897959183674\n",
      "C: 3, Samples: 167, Mean: 0.8622754491017964\n",
      "C: 4, Samples: 142, Mean: 0.8151408450704225\n",
      "C: 5, Samples: 367, Mean: 0.8288828337874659\n",
      "C: 6, Samples: 1114, Mean: 0.8708856971873129\n",
      "C: 7, Samples: 1500, Mean: 0.8959047619047618\n",
      "C: 8, Samples: 1066, Mean: 0.8903611632270169\n",
      "C: 9, Samples: 401, Mean: 0.888057633693544\n",
      "C: 10, Samples: 122, Mean: 0.8811475409836067\n",
      "C: 11, Samples: 57, Mean: 0.9027113237639554\n",
      "C: 12, Samples: 42, Mean: 0.8432539682539681\n",
      "C: 13, Samples: 18, Mean: 0.8717948717948718\n",
      "C: 14, Samples: 6, Mean: 0.8571428571428571\n",
      "C: 15, Samples: 10, Mean: 0.8466666666666667\n",
      "C: 16, Samples: 4, Mean: 0.890625\n",
      "C: 17, Samples: 9, Mean: 0.8431372549019608\n",
      "C: 18, Samples: 6, Mean: 0.8888888888888888\n",
      "C: 19, Samples: 1, Mean: 0.8421052631578947\n",
      "C: 21, Samples: 4, Mean: 0.9166666666666666\n",
      "C: 22, Samples: 2, Mean: 0.8181818181818181\n",
      "C: 23, Samples: 2, Mean: 0.8913043478260869\n",
      "C: 24, Samples: 1, Mean: 0.7916666666666666\n",
      "C: 26, Samples: 2, Mean: 0.7115384615384615\n",
      "C: 28, Samples: 1, Mean: 0.7142857142857143\n",
      "C: 30, Samples: 1, Mean: 0.9\n",
      "C: 32, Samples: 1, Mean: 0.78125\n",
      "C: 33, Samples: 1, Mean: 0.7878787878787878\n",
      "C: 35, Samples: 1, Mean: 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "result_arr2 = [list(x) for x in result_arr]\n",
    "\n",
    "recalls = defaultdict(list)\n",
    "for i in range(len(result_arr2)):\n",
    "    result_arr2[i][0] /= result_arr2[i][2]\n",
    "    result_arr2[i][1] /= result_arr2[i][2]\n",
    "    recalls[result_arr2[i][2]].append(result_arr2[i][1])\n",
    "\n",
    "for c in sorted(recalls.keys()):\n",
    "    print('C: {}, Samples: {}, Mean: {}'.format(c, len(recalls[c]), np.mean(recalls[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ENV(py3_bishal)",
   "language": "python",
   "name": "py3_bishal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
