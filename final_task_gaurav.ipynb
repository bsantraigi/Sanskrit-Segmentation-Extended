{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Ground Truth Reference - Done\n",
    "\n",
    "- Just use the CSV now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pickle\n",
    "import os\n",
    "# Function to open bz2 files (that contains both DCS & SKT info)\n",
    "def open_dsbz2(filename):\n",
    "    with bz2.BZ2File(filename, 'r') as f:\n",
    "        loader = pickle.load(f)\n",
    "    \n",
    "    conflicts_Dict_correct = loader['conflicts_Dict_correct']\n",
    "    nodelist_to_correct_mapping = loader['nodelist_to_correct_mapping']\n",
    "    nodelist_correct = loader['nodelist_correct']\n",
    "    featVMat_correct = loader['featVMat_correct']\n",
    "    featVMat = loader['featVMat']\n",
    "    conflicts_Dict = loader['conflicts_Dict']\n",
    "    nodelist = loader['nodelist']\n",
    "    \n",
    "    return (nodelist_correct, conflicts_Dict_correct, featVMat_correct, nodelist_to_correct_mapping,\\\n",
    "            nodelist, conflicts_Dict, featVMat)\n",
    "\n",
    "def harmonic(P, R):\n",
    "    \"\"\"For Calculation of F-Score since it is the HM of P and R\"\"\"\n",
    "    return(2 * P * R / float(P + R))\n",
    "# Test on a couple of files\n",
    "base_path_bz2 = '/home/rs/15CS91R05/Bishal/NewData/skt_dcs_DS.bz2_1L_bigram_heldout/'\n",
    "base_path_csv = '/home/rs/15CS91R05/gaurav/myTryouts/init_results/prediction_csvs/'\n",
    "pred_csvs = os.listdir(base_path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "nodeSize = defaultdict(dict)\n",
    "countr = 0\n",
    "for item in os.listdir(base_path_bz2):\n",
    "    if item.endswith('.ds.bz2'):\n",
    "        (nodelist_correct, conflicts_Dict_correct, featVMat_correct,\n",
    "         nodelist_to_correct_mapping, nodelist, conflicts_Dict, featVMat) = open_dsbz2(base_path_bz2 + item)\n",
    "        nodeSize[item.split('.')[0]]['nodelist_correct'] = nodelist_correct\n",
    "        nodeSize[item.split('.')[0]]['conflicts_Dict_correct'] = conflicts_Dict_correct\n",
    "        nodeSize[item.split('.')[0]]['featVMat_correct'] = featVMat_correct\n",
    "        nodeSize[item.split('.')[0]]['nodelist_to_correct_mapping'] = nodelist_to_correct_mapping\n",
    "        nodeSize[item.split('.')[0]]['nodelist'] = nodelist\n",
    "        nodeSize[item.split('.')[0]]['conflicts_Dict'] = conflicts_Dict\n",
    "        nodeSize[item.split('.')[0]]['featVMat'] = featVMat\n",
    "        if countr%500 ==0:\n",
    "            print(countr)\n",
    "\n",
    "        countr += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9577"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confDict = list()\n",
    "\n",
    "for fil in nodeSize.keys():\n",
    "    for i,item in enumerate(nodeSize[fil]['nodelist_correct']):\n",
    "        itPos = (nodeSize[fil]['nodelist_to_correct_mapping'][i])\n",
    "        confList = nodeSize[fil]['conflicts_Dict'][itPos]\n",
    "        confDict.append([fil,item.lemma,item.cng,itPos,len(confList)])\n",
    "        \n",
    "len(nodeSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "confDF = pandas.DataFrame.from_records(confDict,columns=['file','lemma','cng','sktCount','conflicts'])\n",
    "\n",
    "confCheck = list(confDF.file.unique())\n",
    "confDF.to_csv('groundTruthReference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodeOn = dict()\n",
    "for item in nodeSize.keys():\n",
    "    nodeOn[item] = len(nodeSize[item]['nodelist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " (nodelist_correct, conflicts_Dict_correct, featVMat_correct,\n",
    "         nodelist_to_correct_mapping, nodelist, conflicts_Dict, featVMat) = open_dsbz2(base_path_bz2 + '39817.ds.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM3 = [\"BM3_NLoss_proc0.csv\",\"BM3_NLoss_proc2.csv\",\"BM3_NLoss_proc1.csv\",\"BM3_NLoss_proc3.csv\"]\n",
    "BM2 = [\"BM2_NLoss_proc0.csv\",\"BM2_NLoss_proc2.csv\",\"BM2_NLoss_proc1.csv\",\"BM2_NLoss_proc3.csv\"]\n",
    "BR2 = [\"BR2_NLoss_proc0.csv\",\"BR2_NLoss_proc2.csv\",\"BR2_NLoss_proc1.csv\",\"BR2_NLoss_proc3.csv\"]\n",
    "BR3 = [\"BR3_NLoss_proc0.csv\",\"BR3_NLoss_proc2.csv\",\"BR3_NLoss_proc1.csv\",\"BR3_NLoss_proc3.csv\"]\n",
    "PM2 = [\"PM2_NLoss_proc0.csv\",\"PM2_NLoss_proc2.csv\",\"PM2_NLoss_proc1.csv\",\"PM2_NLoss_proc3.csv\"]\n",
    "PM3 = [\"PM3_NLoss_proc0.csv\",\"PM3_NLoss_proc2.csv\",\"PM3_NLoss_proc1.csv\",\"PM3_NLoss_proc3.csv\"]\n",
    "PR2 = [\"PR2_NLoss_proc0.csv\",\"PR2_NLoss_proc2.csv\",\"PR2_NLoss_proc1.csv\",\"PR2_NLoss_proc3.csv\"]\n",
    "PR3 = [\"PR3_NLoss_proc0.csv\",\"PR3_NLoss_proc2.csv\",\"PR3_NLoss_proc1.csv\",\"PR3_NLoss_proc3.csv\"]\n",
    "\n",
    "\n",
    "#orig = \"amrith/lemma_label_BM3.csv\"\n",
    "\n",
    "#import pandas\n",
    "#origi = pandas.read_csv(orig,names=['file','lemma','tf'])\n",
    "#origi[origi['file']==39817]\n",
    "#nodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from collections import defaultdict\n",
    "\n",
    "def predLoss(fils):\n",
    "    gt = defaultdict(dict)\n",
    "\n",
    "    for item in fils:\n",
    "        fil = open('amrith/'+item).read().splitlines()\n",
    "        for i,line in enumerate(fil):\n",
    "            if i % 6 == 0:\n",
    "                setCol = line.split(',')\n",
    "                gt[setCol[0]]['predLemma'] = setCol[1:]\n",
    "            if i%6 == 1:\n",
    "                gt[setCol[0]]['predCNG'] = line.split(',')[1:]\n",
    "                if len(gt[setCol[0]]['predLemma']) != len(gt[setCol[0]]['predCNG']):\n",
    "                    print(gt[setCol[0]])\n",
    "            if i%6 == 2:\n",
    "                gt[setCol[0]]['chunkID'] = line.split(',')[1:]\n",
    "                if len(gt[setCol[0]]['predLemma']) != len(gt[setCol[0]]['chunkID']):\n",
    "                    print(gt[setCol[0]])\n",
    "            if i%6 == 3:\n",
    "                gt[setCol[0]]['chunkIDCNG'] = line.split(',')[1:]\n",
    "                if len(gt[setCol[0]]['predLemma']) != len(gt[setCol[0]]['chunkIDCNG']):\n",
    "                    print(gt[setCol[0]])\n",
    "            if i%6 == 4:\n",
    "                gt[setCol[0]]['idInNodeID'] = line.split(',')[1:]\n",
    "                if len(gt[setCol[0]]['predLemma']) != len(gt[setCol[0]]['idInNodeID']):\n",
    "                    print(gt[setCol[0]])\n",
    "            if i%6 == 5:\n",
    "                gt[setCol[0]]['params'] = line.split(',')[1:]\n",
    "\n",
    "            if line.split(',')[0] != setCol[0]:\n",
    "                print(i,setCol,line)\n",
    "                print('breakin')\n",
    "                break\n",
    "    return gt\n",
    "\n",
    "def pdframe(gt):\n",
    "    params = defaultdict(dict)\n",
    "    for item in gt.keys():\n",
    "        tatkal = gt[item]['params']\n",
    "        params[item]['corrWords'],params[item]['corrLemma'] = int(tatkal[0]),int(tatkal[1])\n",
    "        params[item]['dcsSize'],params[item]['predictions'] = int(tatkal[2]),int(tatkal[3])\n",
    "        params[item]['wordPrec'] = params[item]['corrWords']*1.0/params[item]['predictions']\n",
    "        params[item]['wordReca'] = params[item]['corrWords']*1.0/params[item]['dcsSize']\n",
    "        params[item]['lemmaPrec'] = params[item]['corrLemma']*1.0/params[item]['predictions']\n",
    "        params[item]['lemmaReca'] = params[item]['corrLemma']*1.0/params[item]['dcsSize']\n",
    "\n",
    "\n",
    "    initRes = pandas.DataFrame.from_dict(params,orient='index')\n",
    "    return initRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corrWords      5.577485\n",
       "corrLemma      6.148914\n",
       "dcsSize        6.723684\n",
       "predictions    7.025063\n",
       "wordPrec       0.797448\n",
       "wordReca       0.823510\n",
       "lemmaPrec      0.879657\n",
       "lemmaReca      0.908767\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM3gt = predLoss(BM3)\n",
    "BM3pd = pdframe(BM3gt)\n",
    "BM3pd[BM3pd.index!='38206'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodo = pandas.DataFrame.from_dict(nodeOn,orient='index')\n",
    "nodo.columns = ['nodeSKT']\n",
    "aas =BM3pd.join(nodo)\n",
    "aas.to_csv('allFinResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predEnlist = list()\n",
    "for item in BM3gt.keys():\n",
    "    try:\n",
    "        for i,stuff in enumerate(BM3gt[item]['predLemma']):\n",
    "            predEnlist.append([item,stuff,BM3gt[item]['predCNG'][i]])\n",
    "    except:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predEnum = pandas.DataFrame.from_records(predEnlist,columns=['file','lemma','cng'])\n",
    "predEnum.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall Related Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "confDF['lemmaCorr'] = 0\n",
    "confDF['lemmaCNGCorr'] = 0\n",
    "confDF['predictedCNGs'] = 'NIL'\n",
    "def list_duplicates(seq,seq2,findr):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [seq2[idx] for idx,item in enumerate(seq) if item==findr]\n",
    "\n",
    "print(list_duplicates([1, 2, 3, 2, 1, 5, 6, 5, 5, 5],[1, 2, 3, 2, 1, 2, 6, 4, 4, 1],5))\n",
    "for i,item in confDF.iterrows():\n",
    "    try:\n",
    "        if item['lemma'] in BM3gt[item['file']]['predLemma']:\n",
    "            confDF.loc[i,'lemmaCorr'] = 1\n",
    "            cngList = list_duplicates(BM3gt[item['file']]['predLemma'],BM3gt[item['file']]['predCNG'],item['lemma'])\n",
    "            if item['cng'] in cngList:\n",
    "                confDF.loc[i,'lemmaCNGCorr'] = 1\n",
    "                confDF.loc[i,'predictedCNGs'] = item['cng']\n",
    "            else:\n",
    "                confDF.loc[i,'predictedCNGs'] = str(cngList)\n",
    "    except:\n",
    "        print(item)\n",
    "confDF.to_csv('confDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "refGT = pandas.read_csv('confDF.csv')\n",
    "del refGT['Unnamed: 0']\n",
    "predFile = pandas.read_csv('predictions.csv')\n",
    "del predFile['Unnamed: 0']\n",
    "\n",
    "predFile['lemmaCorr'] = 0\n",
    "predFile['lemmaCngCorr'] = 0\n",
    "for i,item in predFile.iterrows():\n",
    "    rest = refGT[refGT['file']==item['file']]\n",
    "    for j,stuff in rest.iterrows():\n",
    "        if stuff['lemma'] == item['lemma']:\n",
    "            predFile.loc[i,'lemmaCorr'] = 1\n",
    "            if stuff['cng'] == item['cng']:\n",
    "                predFile.loc[i,'lemmaCngCorr'] = 1\n",
    "            break\n",
    "predFile.to_csv('BM3predictions2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file', 'lemma', 'cng', 'lemmaCorr', 'lemmaCngCorr'], dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predFile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predFile['confLemma'] = predFile['lemma'] \n",
    "predFile['confCNG'] = predFile['cng'] \n",
    "confLister = list()\n",
    "for i,item in predFile.iterrows():\n",
    "    if item['lemmaCorr'] == 0:\n",
    "        for j,stuff in enumerate(nodeSize[str(item['file'])]['nodelist']):\n",
    "            if stuff.lemma == item['lemma'] and stuff.cng == str(item['cng']):\n",
    "                intera = set(nodeSize[str(item['file'])]['conflicts_Dict'][j]).intersection(set(nodeSize[str(item['file'])]['nodelist_to_correct_mapping'].values()))\n",
    "                for thing in intera:\n",
    "                    confLister.append([item['file'],item['lemma'],item['cng'],nodeSize[str(item['file'])]['nodelist'][thing].lemma,nodeSize[str(item['file'])]['nodelist'][thing].cng])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "gtSeg = pandas.read_csv('groundTruthReference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM2gt = predLoss(PR2)\n",
    "predEnlist = list()\n",
    "for item in BM2gt.keys():\n",
    "    try:\n",
    "        for i,stuff in enumerate(BM2gt[item]['predLemma']):\n",
    "            predEnlist.append([item,stuff,BM2gt[item]['predCNG'][i]])\n",
    "    except:\n",
    "        print(item)\n",
    "predEnum = pandas.DataFrame.from_records(predEnlist,columns=['file','lemma','cng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itLemma = 'PR2Lemma'\n",
    "itLemmaCng = 'PR2LemmaCng'\n",
    "gtSeg[itLemma] = 0\n",
    "gtSeg[itLemmaCng] = 0\n",
    "for i,item in gtSeg.iterrows():\n",
    "    rest = predEnum[predEnum['file']==str(item['file'])]\n",
    "    for j,stuff in rest.iterrows():\n",
    "        if stuff['lemma'] == item['lemma']:\n",
    "            gtSeg.loc[i,itLemma] = 1\n",
    "            if stuff['cng'] == str(item['cng']):\n",
    "                gtSeg.loc[i,itLemmaCng] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gtSeg.to_csv('recallPeer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No need to look down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "missd = confDF[confDF.predictedCNGs.str[0]=='[']\n",
    "confi = defaultdict(dict)\n",
    "for i,item in missd.iterrows():\n",
    "    for j in eval(item['predictedCNGs']):\n",
    "        try:\n",
    "            confi[item['cng']][j] += 1\n",
    "        except:\n",
    "            confi[item['cng']][j] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>pred</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-153</td>\n",
       "      <td>-151</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-19</td>\n",
       "      <td>-10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-151</td>\n",
       "      <td>-153</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-10</td>\n",
       "      <td>-13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-190</td>\n",
       "      <td>-85</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>-210</td>\n",
       "      <td>-153</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>-13</td>\n",
       "      <td>-10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>-210</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-190</td>\n",
       "      <td>-13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-21</td>\n",
       "      <td>-32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>-303</td>\n",
       "      <td>-190</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-10</td>\n",
       "      <td>-36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>31</td>\n",
       "      <td>-210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-10</td>\n",
       "      <td>-32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>-240</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>-10</td>\n",
       "      <td>-263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>-13</td>\n",
       "      <td>-190</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>29</td>\n",
       "      <td>-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>-10</td>\n",
       "      <td>-16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-190</td>\n",
       "      <td>-35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-190</td>\n",
       "      <td>-53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>-53</td>\n",
       "      <td>-50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-16</td>\n",
       "      <td>-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-59</td>\n",
       "      <td>-50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-10</td>\n",
       "      <td>-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-23</td>\n",
       "      <td>-32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-59</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>-210</td>\n",
       "      <td>-151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-33</td>\n",
       "      <td>-32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-11</td>\n",
       "      <td>-32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>80</td>\n",
       "      <td>-190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>89</td>\n",
       "      <td>-240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-37</td>\n",
       "      <td>-47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>81</td>\n",
       "      <td>-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>31</td>\n",
       "      <td>-32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>-190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>159</td>\n",
       "      <td>-153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-190</td>\n",
       "      <td>-43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-190</td>\n",
       "      <td>-73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-190</td>\n",
       "      <td>-243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-190</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>-36</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-246</td>\n",
       "      <td>-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>35</td>\n",
       "      <td>-240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>35</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-59</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-230</td>\n",
       "      <td>-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-10</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-10</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-10</td>\n",
       "      <td>-156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-10</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-10</td>\n",
       "      <td>-159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-10</td>\n",
       "      <td>-230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>59</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-190</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-190</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-190</td>\n",
       "      <td>-210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-190</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-150</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     orig  pred  times\n",
       "194  -153  -151     31\n",
       "206   -19   -10     14\n",
       "320  -151  -153     10\n",
       "270   -10   -13      8\n",
       "232  -190   -85      7\n",
       "375  -210  -153      6\n",
       "420   -13   -10      5\n",
       "373  -210    69      5\n",
       "237  -190   -13      5\n",
       "333   -21   -32      5\n",
       "476  -303  -190      5\n",
       "275   -10   -36      4\n",
       "122    31  -210      4\n",
       "268   -10   -32      4\n",
       "417  -240    35      4\n",
       "276   -10  -263      3\n",
       "421   -13  -190      3\n",
       "179    29   -10      3\n",
       "278   -10   -16      3\n",
       "234  -190   -35      3\n",
       "235  -190   -53      3\n",
       "434   -53   -50      3\n",
       "144   -16   -10      3\n",
       "285   -59   -50      2\n",
       "271   -10   -19      2\n",
       "446   -23   -32      2\n",
       "284   -59    41      2\n",
       "376  -210  -151      2\n",
       "343   -33   -32      2\n",
       "361   -11   -32      2\n",
       "..    ...   ...    ...\n",
       "175    80  -190      1\n",
       "160    89  -240      1\n",
       "142   -37   -47      1\n",
       "133    81  -210      1\n",
       "131    31   -32      1\n",
       "84      3  -210      1\n",
       "70      3  -190      1\n",
       "52    159  -153      1\n",
       "240  -190   -43      1\n",
       "241  -190   -73      1\n",
       "243  -190  -243      1\n",
       "244  -190     3      1\n",
       "367   -36   -10      1\n",
       "350  -246  -210      1\n",
       "318    35  -240      1\n",
       "311    35   -10      1\n",
       "286   -59    81      1\n",
       "46   -230  -210      1\n",
       "279   -10   129      1\n",
       "277   -10    39      1\n",
       "274   -10  -156      1\n",
       "273   -10    49      1\n",
       "272   -10  -159      1\n",
       "269   -10  -230      1\n",
       "263    59   -10      1\n",
       "248  -190   132      1\n",
       "247  -190    29      1\n",
       "246  -190  -210      1\n",
       "245  -190    34      1\n",
       "485  -150    29      1\n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confiList = list()\n",
    "for item in confi.keys():\n",
    "    for stuff in confi[item]:\n",
    "        confiList.append([item,stuff,confi[item][stuff]])\n",
    "confiPD = pandas.DataFrame.from_records(confiList,columns=['orig','pred','times'])\n",
    "confiPD[(confiPD['orig'].str.contains('-')) | (confiPD['pred'].str.contains('-')) ].sort_values('times',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38206 : "
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in BM3gt.keys():\n",
    "    if 'predLemma' not in BM3gt[item]:\n",
    "        print(item,end=\" : \")\n",
    "BM3gt['38206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrWords</th>\n",
       "      <th>corrLemma</th>\n",
       "      <th>dcsSize</th>\n",
       "      <th>predictions</th>\n",
       "      <th>wordPrec</th>\n",
       "      <th>wordReca</th>\n",
       "      <th>lemmaPrec</th>\n",
       "      <th>lemmaReca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [corrWords, corrLemma, dcsSize, predictions, wordPrec, wordReca, lemmaPrec, lemmaReca]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM3pd[BM3pd.index=='38206']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9577"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BM3gt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filesBZ2 = list()\n",
    "for files in os.listdir(base_path_bz2):\n",
    "    filesBZ2.append(files.split('.')[0])\n",
    "len(filesBZ2)\n",
    "\n",
    "for item in filesBZ2:\n",
    "    if item not in gt.keys():\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"6 lines per sentence are there in the csvs\n",
    "\n",
    "lemmas predicted\n",
    "cngs predicted\n",
    "chunk_id\n",
    "pos in chunk\n",
    "id in node.id (you can ignore this)\n",
    "evaluation params (correct words, correct lemmas, dcs_size, predicted_segmentation_size)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Task 1 & 2: Bucket all the files total number of nodes and lemmas\n",
    "    Files Required: the csv files pred_1L_bigram_proc*.csv ==> Contains Predicted outputs\n",
    "    Required output: num_files, P, R, F for the clusters/buckets\n",
    "    Approach: Read the bz2 --> Count number of nodes --> Put in the dictionary --> Finally find P, R, F and same for lemmas\n",
    "\"\"\"\n",
    "node_lengths_skt = set()\n",
    "lemma_lengths_dcs = set()\n",
    "bucket_by_skt_nodes = {}\n",
    "bucket_by_dcs_lemmas = {}\n",
    "for file in pred_csvs:\n",
    "    csv = open(base_path_csv + file, 'r').readlines()\n",
    "    print(\"Pred_File:\", file, len(csv) / 6)\n",
    "    for line in range(0, len(csv), 6):\n",
    "        head_line = csv[line].strip().split(',')\n",
    "        fname = head_line[0]\n",
    "        print(\"Bz2 File number\", fname, line / 6)\n",
    "        data = csv[line + 5].strip().split(',')\n",
    "        word_recall = float(data[1]) / float(data[3])\n",
    "        lemma_recall = float(data[2]) / float(data[3])\n",
    "        word_precision = float(data[1]) / float(data[4])\n",
    "        lemma_precision = float(data[2]) / float(data[4])\n",
    "\n",
    "        (nodelist_correct, conflicts_Dict_correct, featVMat_correct,\n",
    "         nodelist_to_correct_mapping, nodelist, conflicts_Dict, featVMat) = open_dsbz2(base_path_bz2 + fname + '.ds.bz2')\n",
    "\n",
    "        num_nodes_skt = len(nodelist)\n",
    "        num_lemmas_dcs = len(nodelist_correct)\n",
    "\n",
    "        if num_nodes_skt not in node_lengths_skt:\n",
    "            node_lengths_skt.add(num_nodes_skt)\n",
    "            bucket_by_skt_nodes[num_nodes_skt] = {'num_files': 0, 'recall': [0, 0], 'precision': [0, 0]}\n",
    "\n",
    "        bucket_by_skt_nodes[num_nodes_skt]['num_files'] += 1\n",
    "        bucket_by_skt_nodes[num_nodes_skt]['recall'][0] += word_recall\n",
    "        bucket_by_skt_nodes[num_nodes_skt]['recall'][1] += lemma_recall\n",
    "        bucket_by_skt_nodes[num_nodes_skt]['precision'][0] += word_precision\n",
    "        bucket_by_skt_nodes[num_nodes_skt]['precision'][1] += lemma_precision\n",
    "\n",
    "        if num_lemmas_dcs not in lemma_lengths_dcs:\n",
    "            lemma_lengths_dcs.add(num_lemmas_dcs)\n",
    "            bucket_by_dcs_lemmas[num_lemmas_dcs] = {'num_files': 0, 'recall': [0, 0], 'precision': [0, 0]}\n",
    "\n",
    "        bucket_by_dcs_lemmas[num_lemmas_dcs]['num_files'] += 1\n",
    "        bucket_by_dcs_lemmas[num_lemmas_dcs]['recall'][0] += word_recall\n",
    "        bucket_by_dcs_lemmas[num_lemmas_dcs]['recall'][1] += lemma_recall\n",
    "        bucket_by_dcs_lemmas[num_lemmas_dcs]['precision'][0] += word_precision\n",
    "        bucket_by_dcs_lemmas[num_lemmas_dcs]['precision'][1] += lemma_precision\n",
    "print(bucket_by_skt_nodes, bucket_by_dcs_lemmas)\n",
    "\n",
    "\n",
    "for key in bucket_by_skt_nodes:\n",
    "    # Average out P and R\n",
    "    bucket_by_skt_nodes[key]['recall'][0] /= bucket_by_skt_nodes[key]['num_files']\n",
    "    bucket_by_skt_nodes[key]['recall'][1] /= bucket_by_skt_nodes[key]['num_files']\n",
    "    bucket_by_skt_nodes[key]['precision'][0] /= bucket_by_skt_nodes[key]['num_files']\n",
    "    bucket_by_skt_nodes[key]['precision'][1] /= bucket_by_skt_nodes[key]['num_files']\n",
    "    \n",
    "    # Find F-Score\n",
    "    wrd_fscore = harmonic(bucket_by_skt_nodes[key]['precision'][0], bucket_by_skt_nodes[key]['recall'][0])\n",
    "    lma_fscore = harmonic(bucket_by_skt_nodes[key]['precision'][1], bucket_by_skt_nodes[key]['recall'][1])\n",
    "    bucket_by_skt_nodes[key]['fscore'] = [wrd_fscore, lma_fscore]\n",
    "\n",
    "for key in bucket_by_dcs_lemmas:\n",
    "    # Average out P and R\n",
    "    bucket_by_dcs_lemmas[key]['recall'][0] /= bucket_by_dcs_lemmas[key]['num_files']\n",
    "    bucket_by_dcs_lemmas[key]['recall'][1] /= bucket_by_dcs_lemmas[key]['num_files']\n",
    "    bucket_by_dcs_lemmas[key]['precision'][0] /= bucket_by_dcs_lemmas[key]['num_files']\n",
    "    bucket_by_dcs_lemmas[key]['precision'][1] /= bucket_by_dcs_lemmas[key]['num_files']\n",
    "    \n",
    "    # Find F-Score\n",
    "    wrd_fscore = harmonic(bucket_by_dcs_lemmas[key]['precision'][0], bucket_by_dcs_lemmas[key]['recall'][0])\n",
    "    lma_fscore = harmonic(bucket_by_dcs_lemmas[key]['precision'][1], bucket_by_dcs_lemmas[key]['recall'][1])\n",
    "    bucket_by_dcs_lemmas[key]['fscore'] = [wrd_fscore, lma_fscore]\n",
    "\n",
    "with open('bucket_by_nodes.p', 'wb') as f:\n",
    "    pickle.dump(bucket_by_skt_nodes, f)\n",
    "with open('bucket_by_lemmas.p', 'wb') as f:\n",
    "    pickle.dump(bucket_by_dcs_lemmas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 3: CLuster files such that, f = |countcng3| + 1 / |totalcngcount| with |countcng3| >= 2 & f > 0.5\n",
    "and finally find their P, R, F\n",
    "\"\"\"\n",
    "bucket_by_cng3 = {}\n",
    "bucket_by_cng3['num_files'] = 0\n",
    "bucket_by_cng3['files'] = []\n",
    "bucket_by_cng3['precision'] = [0, 0]\n",
    "bucket_by_cng3['recall'] = [0, 0]\n",
    "def strength(count_cng3, total_cngs):\n",
    "    param = (count_cng3 + 1) / float(total_cngs)\n",
    "\n",
    "for file in pred_csvs:\n",
    "    csv = open(base_path_csv + file, 'r').readlines()\n",
    "    print(\"Pred_File:\", file, len(csv) / 6)\n",
    "    for line in range(0, len(csv), 6):\n",
    "        cngs = csv[line + 1].strip().split(',')\n",
    "        count_cng3 = cngs.count(3)\n",
    "        if count_cng3 < 2:\n",
    "            continue\n",
    "\n",
    "        total_cngs = len(cngs)\n",
    "        strnth = strength(count_cng3, total_cngs)\n",
    "        if strnth <= 0.5:\n",
    "            continue\n",
    "        \n",
    "        head_line = csv[line].strip().split(',')\n",
    "        fname = head_line[0]\n",
    "        print(\"Bz2 File number\", fname, line / 6)\n",
    "        bucket_by_cng3['files'].append(fname)\n",
    "        bucket_by_cng3['num_files'] += 1\n",
    "        \n",
    "        data = csv[line + 5].strip().split(',')\n",
    "        word_recall = float(data[1]) / float(data[3])\n",
    "        lemma_recall = float(data[2]) / float(data[3])\n",
    "        word_precision = float(data[1]) / float(data[4])\n",
    "        lemma_precision = float(data[2]) / float(data[4])\n",
    "        \n",
    "        bucket_by_cng3['recall'][0] += word_recall\n",
    "        bucket_by_cng3['recall'][1] += lemma_recall\n",
    "        bucket_by_cng3['precision'][0] += word_precision\n",
    "        bucket_by_cng3['precision'][1] += lemma_precision\n",
    "\n",
    "# Average out P and R\n",
    "bucket_by_cng3['recall'][0] /= bucket_by_cng3['num_files']\n",
    "bucket_by_cng3['recall'][1] /= bucket_by_cng3['num_files']\n",
    "bucket_by_cng3['precision'][0] /= bucket_by_cng3['num_files']\n",
    "bucket_by_cng3['precision'][1] /= bucket_by_cng3['num_files']\n",
    "\n",
    "# F-Scores\n",
    "wrd_fscore = harmonic(bucket_by_cng3['precision'][0], bucket_by_cng3['recall'][0])\n",
    "lma_fscore = harmonic(bucket_by_cng3['precision'][1], bucket_by_cng3['recall'][1])\n",
    "\n",
    "bucket_by_cng3['fscore'] = [wrd_fscore, lma_fscore]\n",
    "\n",
    "with open('bucket_by_cng3.p', 'wb') as f:\n",
    "    pickle.dump(bucket_by_cng3, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### W"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ENV(py3_bishal)",
   "language": "python",
   "name": "py3_bishal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
